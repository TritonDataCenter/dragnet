#!/usr/bin/env node
/* vim: set syn=javascript: */

/*
 * dnl: create, query, and destroy indexes on data stored in Manta
 */

var timeStarted = process.hrtime();
var mod_assert = require('assert');
var mod_bunyan = require('bunyan');
var mod_dashdash = require('dashdash');
var mod_manta = require('manta');
var mod_path = require('path');
var mod_tab = require('tab');
var VError = require('verror');
var sprintf = require('extsprintf').sprintf;

var mod_dragnet = require('../lib/dragnet');
var mod_dragnet_impl = require('../lib/dragnet-impl'); /* XXX */
var FileDataSource = require('../lib/source-file');
var FileSetDataSource = require('../lib/source-fileset');
var MantaDataSource = require('../lib/source-manta');
var SkinnerFlattener = require('../lib/skinner-flattener');
var attrsParse = require('../lib/attr-parser');

var timeRequireDone = process.hrtime(timeStarted);

/*
 * Program name and usage
 */
var dnArg0 = mod_path.basename(process.argv[1]);
var dnUsage = [
    'usage: dnl scan-file   [-b|--breakdowns COLUMN[,COLUMN...]]',
    '                      [-f|--filter FILTER]',
    '                      [--before END_TIMESTAMP] [--after START_TIMESTAMP]',
    '                      [--time-field=FIELDNAME]',
    '                      [--data-format json|json-skinner]',
    '                      [--counters] [--points] [--warnings]',
    '                      DATA_FILE',
    '',
    '       dnl scan-tree   [-b|--breakdowns COLUMN[,COLUMN...]]',
    '                      [-f|--filter FILTER]',
    '                      [--before END_TIMESTAMP] [--after START_TIMESTAMP]',
    '                      [--time-field=FIELDNAME]',
    '                      [--data-format json|json-skinner]',
    '                      [--time-format=TIME_FORMAT] ',
    '                      [--counters] [--points] [--warnings]',
    '                      DATA_DIRECTORY',
    '',
    '       dnl scan-manta  [-b|--breakdowns COLUMN[,COLUMN...]]',
    '                      [-f|--filter FILTER]',
    '                      [--before END_TIMESTAMP] [--after START_TIMESTAMP]',
    '                      [--time-field=FIELDNAME]',
    '                      [--data-format json|json-skinner]',
    '                      [--time-format=TIME_FORMAT] ',
    '                      [--assetroot=ASSETROOT]',
    '                      [--extra-reduce-phases N] ',
    '                      [--extra-reduce-count C]',
    '                      [--dry-run] [--counters] [--points] [--warnings]',
    '                      DATA_DIRECTORY',
    '',
    '       dnl index-file  [-c|--columns COLUMN[,COLUMN...]]',
    '                      [-f|--filter FILTER]',
    '                      [--before END_TIMESTAMP] [--after START_TIMESTAMP]',
    '                      [--data-format json|json-skinner]',
    '                      [-i|--interval hour|day]',
    '                      [--counters] [--warnings]',
    '                      DATA_FILE INDEX_FILE',
    '',
    '       dnl index-tree  [-c|--columns COLUMN[,COLUMN...]]',
    '                      [-f|--filter FILTER]',
    '                      [--before END_TIMESTAMP] [--after START_TIMESTAMP]',
    '                      [--time-format=TIME_FORMAT]',
    '                      [--data-format json|json-skinner]',
    '                      [-i|--interval hour|day]',
    '                      [--counters] [--warnings]',
    '                      DATA_DIRECTORY INDEX_DIRECTORY',
    '',
    '       dnl index-manta [-c|--columns COLUMN[,COLUMN...]]',
    '                      [-f|--filter FILTER]',
    '                      [--before END_TIMESTAMP] [--after START_TIMESTAMP]',
    '                      [--time-format=TIME_FORMAT]',
    '                      [--data-format json|json-skinner]',
    '                      [-i|--interval hour|day]',
    '                      [--assetroot=ASSETROOT]',
    '                      [--extra-reduce-phases N] ',
    '                      [--extra-reduce-count C]',
    '                      [--dry-run] [--counters] [--warnings]',
    '                      DATA_DIRECTORY INDEX_DIRECTORY',
    '',
    '       dnl rollup-tree [-c|--columns COLUMN[,COLUMN...]]',
    '                      [-f|--filter FILTER]',
    '                      [--before END_TIMESTAMP] [--after START_TIMESTAMP]',
    '                      [-i|--interval hour|day]',
    '                      [-s|--source hour]',
    '                      [--counters] [--warnings]',
    '                      INDEX_DIRECTORY',
    '',
    '       dnl query-file [-b|--breakdowns COLUMN[,COLUMN...]]',
    '                     [-f|--filter FILTER]',
    '                     [--before END_TIMESTAMP] [--after START_TIMESTAMP]',
    '                     [--time-field TIME_FIELD]',
    '                     [--points] [--counters]',
    '                     INDEX_FILE',
    '',
    '       dnl query-tree [-b|--breakdowns COLUMN[,COLUMN...]]',
    '                     [-f|--filter FILTER]',
    '                     [--before END_TIMESTAMP] [--after START_TIMESTAMP]',
    '                     [--time-field TIME_FIELD]',
    '                     [--points] [--counters]',
    '                     INDEX_DIRECTORY',
    '',
    '       dnl query-mjob [-b|--breakdowns COLUMN[,COLUMN...]]',
    '                     [-f|--filter FILTER]',
    '                     [--before END_TIMESTAMP] [--after START_TIMESTAMP]',
    '                     [--time-field TIME_FIELD]',
    '                     [--assetroot=ASSETROOT]',
    '                     [--points] [--counters]',
    '                     INDEX_DIRECTORY',
    '',
    '       dnl query-mget [-b|--breakdowns COLUMN[,COLUMN...]]',
    '                     [-f|--filter FILTER]',
    '                     [--before END_TIMESTAMP] [--after START_TIMESTAMP]',
    '                     [--time-field TIME_FIELD]',
    '                     [--assetroot=ASSETROOT]',
    '                     [--points] [--counters]',
    '                     INDEX_DIRECTORY CACHE_DIRECTORY'
].join('\n');

/*
 * Subcommands
 */
var dnCmds = {
    'index-file': cmdIndexFile,
    'index-tree': cmdIndexTree,
    'index-manta': cmdIndexManta,
    'query-file': cmdQueryFile,
    'query-tree': cmdQueryTree,
    'query-mjob': cmdQueryMjob,
    'query-mget': cmdQueryMget,
    'rollup-tree': cmdRollupTree,
    'scan-file': cmdScanFile,
    'scan-tree': cmdScanTree,
    'scan-manta': cmdScanManta
};

/*
 * dashdash command-line option configuration (common to all subcommands)
 */
var dnOptions = [ {
    'names': [ 'after', 'A' ],
    'type': 'date'
}, {
    'names': [ 'before', 'B' ],
    'type': 'date'
}, {
    'names': [ 'filter', 'f' ],
    'type': 'string'
}, {
    'names': [ 'time-field' ],
    'type': 'string'
}, {
    'names': [ 'breakdowns', 'b' ],
    'type': 'arrayOfString',
    'default': []
}, {
    'names': [ 'columns', 'c' ],
    'type': 'arrayOfString',
    'default': []
}, {
    'names': [ 'interval', 'i' ],
    'type': 'string',
    'default': 'hour'
}, {
    'names': [ 'indexroot', 'I' ],
    'type': 'string'
}, {
    'names': [ 'source', 's' ],
    'type': 'string'
}, {
    'names': [ 'data-format' ],
    'type': 'string',
    'default': 'json'
}, {
    'names': [ 'time-format' ],
    'type': 'string'
}, {
    'names': [ 'warnings' ],
    'type': 'bool'
}, {
    'names': [ 'counters' ],
    'type': 'bool'
}, {
    'names': [ 'points' ],
    'type': 'bool'
}, {
    'names': [ 'dry-run', 'n' ],
    'type': 'bool'
}, {
    'names': [ 'raw' ],
    'type': 'bool'
}, {
    'names': [ 'assetroot' ],
    'type': 'string',
    'default': '/manta/public/dragnet/assets'
}, {
    'names': [ 'extra-reduce-phases' ],
    'type': 'number',
    'default': 0
}, {
    'names': [ 'extra-reduce-count' ],
    'type': 'number',
    'default': 2
} ];

/*
 * Internal state
 */
var dnDone = false;		/* went through normal exit path */
var dnTrackTime = false;	/* option to print program execution time */
var dnLog;			/* bunyan logger */
var dnStream;			/* output stream (for debugging) */

/*
 * Main program entry point.
 */
function main()
{
	var optind, cmdname, cmdfunc;

	optind = 2;
	if (process.argv[optind] == '-t') {
		dnTrackTime = true;
		optind++;
	}

	if (process.argv.length < optind + 1)
		usage(new VError('no command specified'));

	cmdname = process.argv[optind];
	if (!dnCmds.hasOwnProperty(cmdname))
		usage(new VError('no such command: "%s"', cmdname));

	dnLog = new mod_bunyan({
	    'name': 'dragnet',
	    'level': process.env['LOG_LEVEL'] || 'warn'
	});

	process.stdout.on('error', function (err) {
		if (err.code == 'EPIPE') {
			dnDone = true;
			process.exit(0);
		}
		throw (err);
	});
	cmdfunc = dnCmds[cmdname];
	cmdfunc(cmdname, process.argv.slice(optind + 1));
}

/*
 * usage([error]): pretty-print an error message, then print usage information,
 * then exit.
 */
function usage(err)
{
	if (err)
		console.error('%s: %s', dnArg0, err.message);

	dnDone = true;
	console.error(dnUsage);
	process.exit(2);
}

/*
 * fatal(error): pretty-print an error message and exit.
 */
function fatal(err)
{
	dnDone = true;
	console.error('%s: %s', dnArg0, err.message);
	process.exit(1);
}

/*
 * warn(context, kind, error): emit a warning.  This isn't just for arbitrary
 * warnings, but specifically "vstream"-style warnings, which may have a
 * "context" and always have a "kind" and an "error".
 */
function warn(context, kind, error)
{
	console.error('warn: %s', error.message);
	if (context !== null)
		console.error('    at ' + context.label());
}

/*
 * Given a list of option names, return the corresponding dashdash
 * configuration.
 */
function dnOptionConfig(useroptions)
{
	var rv, i, j;
	var options;

	rv = [];
	options = useroptions.concat([ 'warnings', 'counters' ]);
	for (i = 0; i < options.length; i++) {
		for (j = 0; j < dnOptions.length; j++) {
			if (dnOptions[j].names.indexOf(options[i]) != -1)
				break;
		}

		if (j == dnOptions.length)
			throw (new VError('unknown option: "%s"', options[i]));

		rv.push(dnOptions[j]);
	}

	return (rv);
}

/*
 * Given "options" as returned by dashdash's parser and a "field" whose value
 * should be an array of strings, split up each entry of the field's value on
 * commas.  This is because we want all of these to be equivalent:
 *
 *    -b one,two,three
 *    -b one,two -b three
 *    -b one -b two -b three
 */
function dnExpandArray(options, field)
{
	if (!Array.isArray(options[field]))
		return;

	var tmp = options[field];
	options[field] = [];
	tmp.forEach(function (v) {
		var list = attrsParse(v);
		if (list instanceof Error)
			fatal(new VError(list, 'bad value for "%s" ("%s")',
			    field, v));
		list.forEach(function (s) { options[field].push(s); });
	});
}

/*
 * Given "argv" (as trimmed by main()) and a list of user options, parse the
 * arguments and return the dashdash "options" object.
 */
function dnParseArgs(argv, useroptions)
{
	var parser, rv;

	parser = mod_dashdash.createParser({
	    'options': dnOptionConfig(useroptions),
	    'interspersed': false,
	    'allowUnknown': false
	});

	try {
		rv = parser.parse({ 'argv': argv, 'slice': 0 });
	} catch (ex) {
		usage(ex);
	}

	dnExpandArray(rv, 'columns');
	dnExpandArray(rv, 'breakdowns');
	return (rv);
}

/*
 * Check for missing or extra NON-option arguments.
 */
function dnCheckArgCount(options, expected)
{
	if (options._args.length < expected)
		usage(new Error('missing arguments'));

	if (options._args.length > expected)
		usage(new Error('extra arguments'));
}

/*
 * "dnl index-file" implementation
 */
function cmdIndexFile(cmdname, argv)
{
	var options, filename, indexfilename, source;

	options = dnParseArgs(argv, [
	    'before', 'after', 'filter', 'time-field',
	    'columns', 'data-format'
	]);

	dnCheckArgCount(options, 2);
	filename = options._args[0];
	indexfilename = options._args[1];
	source = new FileDataSource({
	    'log': dnLog,
	    'filename': filename
	});

	dnIndex(source, options, {
	    'source': 'raw',
	    'format': options.data_format,
	    'filename': indexfilename
	}, function () {
		console.error('index "%s" created', indexfilename);
	});
}

/*
 * "dnl index-tree" implementation
 */
function cmdIndexTree(cmdname, argv)
{
	var options, dataroot, indexroot, source;

	options = dnParseArgs(argv, [
	    'before', 'after', 'filter', 'time-field', 'time-format',
	    'columns', 'data-format', 'interval'
	]);

	dnCheckArgCount(options, 2);
	dataroot = options._args[0];
	indexroot = options._args[1];

	if (options.time_format === undefined &&
	    (options.before !== undefined || options.after !== undefined)) {
		usage(new VError('must specify --time-format with ' +
		    '--before or --after'));
	}

	source = new FileSetDataSource({
	    'log': dnLog,
	    'dataroot': dataroot,
	    'indexroot': indexroot
	});

	dnIndex(source, options, {
	    'source': 'raw',
	    'format': options.data_format,
	    'timeFormat': options.time_format || undefined,
	    'indexroot': indexroot
	}, function () {
		console.error('indexes created');
	});
}

/*
 * "dnl index-manta" implementation
 */
function cmdIndexManta(cmdname, argv)
{
	var options, dataroot, indexroot, client, source;

	options = dnParseArgs(argv, [
	    'before', 'after', 'filter', 'time-field', 'time-format',
	    'columns', 'data-format', 'interval', 'dry-run',
	    'extra-reduce-phases', 'extra-reduce-count', 'assetroot'
	]);

	dnCheckArgCount(options, 2);
	dataroot = options._args[0];
	indexroot = options._args[1];

	if (options.time_format === undefined &&
	    (options.before !== undefined || options.after !== undefined)) {
		usage(new VError('must specify --time-format with ' +
		    '--before or --after'));
	}

	client = dnMantaClient(dnLog);
	source = new MantaDataSource({
	    'log': dnLog,
	    'manta': client,
	    'dataroot': dataroot,
	    'assetroot': options.assetroot
	});

	dnIndex(source, options, {
	    'source': 'raw',
	    'dryRun': options.dry_run,
	    'format': options.data_format,
	    'timeFormat': options.time_format || undefined,
	    'indexroot': indexroot,
	    'extraReduceCount': options.extra_reduce_count,
	    'extraReducePhases': options.extra_reduce_phases
	}, function () {
		if (!options.dry_run)
			console.error('indexes created');
		client.close();
	});
}

/*
 * "dnl rollup-tree" implementation
 */
function cmdRollupTree(cmdname, argv)
{
	var options, dataroot, indexroot, source;

	options = dnParseArgs(argv, [
	    'before', 'after', 'filter', 'time-field',
	    'columns', 'interval', 'source'
	]);

	dnCheckArgCount(options, 1);
	indexroot = options._args[0];

	source = new FileSetDataSource({
	    'log': dnLog,
	    'dataroot': dataroot,
	    'indexroot': indexroot
	});

	dnIndex(source, options, {
	    'source': options.source,
	    'format': options.data_format,
	    'timeFormat': options.time_format || undefined,
	    'indexroot': indexroot
	}, function () {
		console.error('indexes created');
	});
}

/*
 * Common function used by "dnl index-file", "dnl index-tree", and "dnl
 * rollup-tree".
 */
function dnIndex(source, options, indexargs, callback)
{
	var indexconfig, indexoptions, ic, op;

	indexconfig = {};
	indexoptions = { 'index': indexconfig };
	indexconfig.columns = options.columns;
	indexconfig.interval = options.interval || 'hour';
	if (options.after)
		indexoptions.timeAfter = options.after;
	if (options.before)
		indexoptions.timeBefore = options.before;
	if (options.filter) {
		try {
			indexconfig.filter = JSON.parse(options.filter);
		} catch (ex) {
			usage(new VError(ex, 'invalid filter'));
		}
	}
	ic = mod_dragnet.indexLoad(indexoptions);
	if (ic instanceof Error)
		fatal(ic);

	mod_assert.ok(indexargs.hasOwnProperty('source'));
	mod_assert.ok(indexargs.hasOwnProperty('format'));
	mod_assert.ok(indexargs.hasOwnProperty('filename') ||
	     indexargs.hasOwnProperty('indexroot'));
	indexargs.index = ic;
	op = source.index(indexargs);
	op.on('error', fatal);
	dnStream = op;

	if (options.warnings)
		dnShowWarnings(op);

	op.on('flushed', function () {
		callback();
		if (options.counters)
			dnPrintCounters(op);
		dnDone = true;
	});
}

/*
 * "dnl query-file" implementation
 */
function cmdQueryFile(cmdname, argv)
{
	var options, indexfilename, source;

	options = dnParseArgs(argv, [
	    'before', 'after', 'filter', 'time-field', 'breakdowns', 'raw',
	    'points'
	]);

	dnCheckArgCount(options, 1);
	indexfilename = options._args[0];
	source = new FileDataSource({ 'log': dnLog });
	dnQuery(source, options, { 'filename': indexfilename });
}

/*
 * "dnl query-tree" implementation
 */
function cmdQueryTree(cmdname, argv)
{
	var options, indexroot, source;

	options = dnParseArgs(argv, [
	    'before', 'after', 'filter', 'time-field', 'breakdowns', 'raw',
	    'points'
	]);

	dnCheckArgCount(options, 1);
	indexroot = options._args[0];
	source = new FileSetDataSource({
	    'log': dnLog,
	    'indexroot': indexroot
	});
	dnQuery(source, options, { 'indexroot': indexroot });
}

/*
 * "dnl query-mjob" implementation
 */
function cmdQueryMjob(cmdname, argv)
{
	var options, indexroot, client, source;

	options = dnParseArgs(argv, [
	    'before', 'after', 'filter', 'time-field', 'breakdowns', 'raw',
	    'points', 'dry-run', 'assetroot'
	]);

	dnCheckArgCount(options, 1);
	indexroot = options._args[0];
	client = dnMantaClient(dnLog);
	source = new MantaDataSource({
	    'log': dnLog,
	    'manta': client,
	    'assetroot': options.assetroot
	});
	dnQuery(source, options, {
	    'dryRun': options.dry_run,
	    'indexroot': indexroot
	}, function () {
		client.close();
	});
}

/*
 * "dnl query-mget" implementation
 */
function cmdQueryMget(cmdname, argv)
{
	var options, indexroot, cacheroot, client, mantasource, treesource, qc;

	options = dnParseArgs(argv, [
	    'before', 'after', 'filter', 'time-field', 'breakdowns', 'raw',
	    'points'
	]);

	dnCheckArgCount(options, 2);
	indexroot = options._args[0];
	cacheroot = options._args[1];

	client = dnMantaClient(dnLog);
	mantasource = new MantaDataSource({
	    'log': dnLog,
	    'manta': client
	});
	treesource = new FileSetDataSource({
	    'log': dnLog,
	    'indexroot': cacheroot
	});

	qc = dnQueryConstructQuery(options);
	mantasource.queryFetchOnly({
	    'indexroot': indexroot,
	    'cacheroot': cacheroot,
	    'query': qc
	}, function (err) {
		if (err)
			fatal(err);

		dnLog.info('fetched all indexes');
		client.close();
		dnQuery(treesource, options, { 'indexroot': cacheroot });
	});
}

function dnQueryConstructQuery(options)
{
	var queryconfig;

	queryconfig = {};
	queryconfig.breakdowns = options.breakdowns;
	if (options.after)
		queryconfig.timeAfter = options.after;
	if (options.before)
		queryconfig.timeBefore = options.before;
	if (options.time_field) {
		/*
		 * XXX This shouldn't be necessary.  We should record
		 * the time field into an index configuration file and
		 * then read that here.
		 */
		queryconfig.timeField = options.time_field;
	}
	if (options.filter) {
		try {
			queryconfig.filter = JSON.parse(options.filter);
		} catch (ex) {
			return (new VError(ex, 'invalid filter'));
		}
	}

	return (mod_dragnet.queryLoad({ 'query': queryconfig }));
}

/*
 * Common function used by "dnl query-file" and "dnl query-tree".
 */
function dnQuery(source, options, queryargs, callback)
{
	var qc, op;

	qc = dnQueryConstructQuery(options);
	if (qc instanceof Error)
		fatal(qc);

	mod_assert.ok(queryargs.hasOwnProperty('filename') ||
	    queryargs.hasOwnProperty('indexroot'));
	queryargs.query = qc;

	op = source.query(queryargs);
	dnShowWarnings(op);
	dnOutput(qc, options, op, callback);
}

/*
 * "dnl scan-file" implementation.
 */
function cmdScanFile(cmdname, argv)
{
	var options, filename, source;

	options = dnParseArgs(argv, [
	    'before', 'after', 'filter', 'time-field', 'breakdowns', 'raw',
	    'points', 'data-format'
	]);

	dnCheckArgCount(options, 1);
	filename = options._args[0];
	source = new FileDataSource({ 'log': dnLog, 'filename': filename });
	dnScan(source, options, {});
}

/*
 * "dnl scan-tree" implementation.
 */
function cmdScanTree(cmdname, argv)
{
	var options, dataroot, source;

	options = dnParseArgs(argv, [
	    'before', 'after', 'filter', 'time-field', 'breakdowns', 'raw',
	    'points', 'data-format', 'time-format'
	]);

	dnCheckArgCount(options, 1);
	dataroot = options._args[0];
	source = new FileSetDataSource({
	    'log': dnLog,
	    'dataroot': dataroot
	});
	dnScan(source, options, { 'timeFormat': options.time_format });
}

function dnMantaClient(log)
{
	var client;

	client = mod_manta.createBinClient({
	    'log': log.child({ 'component': 'manta' })
	});

	/* Bad, manta client! */
	process.removeAllListeners('uncaughtException');

	return (client);
}

/*
 * "dnl scan-manta" implementation.
 */
function cmdScanManta(cmdname, argv)
{
	var options, dataroot, client, source;

	options = dnParseArgs(argv, [
	    'before', 'after', 'filter', 'time-field', 'breakdowns', 'raw',
	    'points', 'data-format', 'time-format', 'dry-run',
	    'extra-reduce-phases', 'extra-reduce-count', 'assetroot'
	]);

	dnCheckArgCount(options, 1);
	dataroot = options._args[0];

	client = dnMantaClient(dnLog);
	source = new MantaDataSource({
	    'log': dnLog,
	    'manta': client,
	    'dataroot': dataroot,
	    'assetroot': options.assetroot
	});

	dnScan(source, options, {
	    'dryRun': options.dry_run,
	    'timeFormat': options.time_format,
	    'extraReduceCount': options.extra_reduce_count,
	    'extraReducePhases': options.extra_reduce_phases
	}, function () {
		client.close();
	});
}

/*
 * Common function used by "dnl scan-file" and "dnl scan-tree".
 */
function dnScan(source, options, scanargs, callback)
{
	var queryconfig, qc, op;

	queryconfig = {};
	queryconfig.breakdowns = options.breakdowns;
	if (options.after)
		queryconfig.timeAfter = options.after;
	if (options.before)
		queryconfig.timeBefore = options.before;
	if (options.time_field)
		queryconfig.timeField = options.time_field;
	if (options.filter) {
		try {
			queryconfig.filter = JSON.parse(options.filter);
		} catch (ex) {
			fatal(new VError(ex, 'invalid filter'));
		}
	}
	qc = mod_dragnet.queryLoad({ 'query': queryconfig });
	if (qc instanceof Error)
		fatal(qc);

	scanargs.query = qc;
	scanargs.format = options.data_format;
	op = source.scan(scanargs);
	if (options.warnings)
		dnShowWarnings(op);
	dnOutput(qc, options, op, callback);
}

/*
 * Given a stream in a "vstream" pipeline, walk the whole pipeline and attach a
 * "warn" listener for each one that will print warnings to the console.
 */
function dnShowWarnings(op)
{
	op.vsHead().vsWalk(function (s) { s.on('warn', warn); });
}

/*
 * Given a stream in a "vstream" pipeline, walk the whole pipeline and emit all
 * non-zero counters for each stream.
 */
function dnPrintCounters(stream)
{
	stream.vsHead().vsWalk(function (s) {
		s.vsDumpCounters(process.stderr);
	});
}

/*
 * Given a query configuration, command-line options, and a stream that will
 * emit results, print out the results.  This takes care of looking at the "raw"
 * and "points" options and flattening data points as needed.  This is used for
 * both "query" and "scan" (which output the same thing).
 */
function dnOutput(query, options, op, callback)
{
	var output, stream;

	op.on('error', fatal);

	if (options.points) {
		stream = op;
	} else {
		stream = new SkinnerFlattener({
		    'skinnerOptions': mod_dragnet_impl.queryAggrStreamConfig(
		        { 'query': query })
		});
		op.pipe(stream);
	}

	dnStream = stream;
	output = options.raw || options.points ? dnOutputRaw : dnOutputPretty;
	stream.on('data', function (rows) {
		output({ 'query': query, 'rows': rows });
	});

	stream.on('end', function () {
		if (options.counters)
			dnPrintCounters(stream);
		dnDone = true;
		if (callback)
			callback();
	});
}

/*
 * Outputter that emits data as plain JSON.
 */
function dnOutputRaw(results)
{
	console.log(JSON.stringify(results.rows));
}

/*
 * Outputter that pretty-prints data.
 */
function dnOutputPretty(results)
{
	var coldefs, tablefields, quantized;

	coldefs = results.query.qc_breakdowns;
	quantized = coldefs.length > 0 && coldefs[coldefs.length - 1].aggr;

	/*
	 * Take a pass over the results and replace quantized values with the
	 * real values.  Do the same to replace timestamps.
	 */
	coldefs.forEach(function (c, j) {
		var bucketizer;

		if (quantized && j == coldefs.length - 1)
			return;

		if (results.query.qc_bucketizers.hasOwnProperty(c.name)) {
			bucketizer = results.query.qc_bucketizers[c.name];
			results.rows.forEach(function (row) {
				row[j] = bucketizer.bucketMin(row[j]);
			});
		}

		if (c.hasOwnProperty('date')) {
			results.rows.forEach(function (row) {
				row[j] = new Date(row[j] * 1000).toISOString();
			});
		}
	});

	if (quantized) {
		dnOutputPrettyQuantized(results);
		return;
	}

	tablefields = coldefs.map(function (c) {
		return ({
		    'label': c.name.toUpperCase(),
		    'width': c.name.toUpperCase().toString().length
		});
	});
	tablefields.push({
	    'label': 'VALUE',
	    'width': 'VALUE'.length,
	    'align': 'right'
	});

	if (results.rows.length === 0)
		return;

	if (results.rows.length == 1 && typeof (results.rows[0]) == 'number')
		results.rows[0] = [ results.rows[0] ];

	results.rows.forEach(function (row) {
		var width;

		mod_assert.ok(row.length == coldefs.length + 1);
		coldefs.forEach(function (c, j) {
			if (typeof (row[j]) == 'number')
				tablefields[j].align = 'right';
			else
				mod_assert.equal('string', typeof (row[j]));

			width = row[j].toString().length;
			if (tablefields[j].width < width)
				tablefields[j].width = width;
		});

		mod_assert.equal('number', typeof (row[row.length - 1]));
		width = row[row.length - 1].toString().length;
		if (tablefields[row.length - 1].width < width)
			tablefields[row.length - 1].width = width;
	});

	mod_tab.emitTable({
	    'columns': tablefields,
	    'rows': results.rows.slice(0).sort(function (a, b) {
		var j, d;

		mod_assert.ok(Array.isArray(a) && Array.isArray(b));
		mod_assert.equal(a.length, b.length);
		for (j = 0; j < a.length; j++) {
			if (typeof (a[j]) == 'string')
				d = a[j].localeCompare(b[j]);
			else
				d = a[j] - b[j];

			if (d !== 0)
				return (d);
		}

		return (0);
	    })
	});
}

function dnOutputPrettyQuantized(results)
{
	var coldefs, quantizedcol, stream, bucketizer, last, distr, groups;

	coldefs = results.query.qc_breakdowns;
	quantizedcol = coldefs[coldefs.length - 1];
	mod_assert.equal(typeof (quantizedcol.aggr), 'string');
	bucketizer = results.query.qc_bucketizers[quantizedcol.name];
	mod_assert.ok(bucketizer !== null);
	stream = process.stdout;
	groups = [];
	last = null;
	distr = [];

	results.rows.forEach(function (row) {
		var discrete_values = row.slice(0, coldefs.length - 1);
		var key = discrete_values.join(', ') + '\n';
		if (distr.length > 0 && key !== last) {
			groups.push({
			    'label': last,
			    'distr': distr
			});
		}

		if (key !== last) {
			last = key;
			distr = [];
		}

		distr.push([ row[coldefs.length - 1], row[coldefs.length] ]);
	});

	if (last !== null) {
		groups.push({
		    'label': last,
		    'distr': distr
		});
	}

	groups.sort(function (a, b) {
		return (a.label.localeCompare(b.label));
	});
	groups.forEach(function (g, i) {
		if (i !== 0)
			stream.write('\n');
		stream.write(g.label);
		dnPrintDistribution(stream, g.distr, bucketizer,
		    quantizedcol.hasOwnProperty('date'));
	});
}

function dnPrintDistribution(stream, distr, bucketizer, asdate)
{
	var fmt, total, count, normalized, dots;
	var bi, di, i, min;

	if (asdate) {
		stream.write('          ');
		fmt = '  %24s |%s %s\n';
	} else {
		fmt = '%16s |%s %s\n';
	}
	stream.write('           ');
	stream.write(
	    'value  ------------- Distribution ------------- count\n');

	if (distr.length === 0)
		return;

	total = 0;
	for (di = 0; di < distr.length; di++)
		total += distr[di][1];

	/*
	 * If there's a large number of empty buckets at the beginning, we're
	 * probably lookint at large values (like timestamps) where the user
	 * doesn't really want us to print all the leading empty buckets.
	 */
	if (distr[0][0] > 100)
		bi = distr[0][0];
	else
		bi = 0;

	for (di = 0; di < distr.length + 1; bi++) {
		if (di == distr.length) {
			count = 0;
			di++;
		} else if (distr[di][0] == bi) {
			count = distr[di][1];
			di++;
		} else {
			count = 0;
		}

		normalized = Math.round(40 * count / total);
		dots = '';
		for (i = 0; i < normalized; i++)
			dots += '@';
		for (; i < 40; i++)
			dots += ' ';

		min = bucketizer.bucketMin(bi);
		stream.write(sprintf(fmt, asdate ?
		    new Date(min * 1000).toISOString() : min.toString(),
		    dots, count));
	}
}

/*
 * Add an "exit" listener to check whether we exited prematurely.  Node exits
 * with success when there's no more work to do, but there are many kinds of
 * bugs that result in accidentally leaving no work to do (as when failing to
 * invoke a pipeline callback without scheduling additional work).  To make sure
 * we don't accidentally do this, we explicitly set dnDone when we're ready to
 * exit and we consider it a serious error if we're about to exit 0 with dnDone
 * false.
 *
 * This implementation does not affect --abort-on-uncaught-exception since that
 * will trigger an abort before we get here.  Nor does this paper over uncaught
 * exceptions, since we'll come through here with a non-zero code, won't do
 * anything, and Node will dump the exception like it normally does.
 */
process.on('exit', function (code) {
	if (dnTrackTime) {
		var timeDone = process.hrtime(timeStarted);
		console.error('timing stats:');
		console.error('    require: ', timeRequireDone);
		console.error('    total:   ', timeDone);
	}

	if (code === 0 && !dnDone) {
		console.error('ERROR: internal error: premature exit');
		if (dnStream !== undefined) {
			dnStream.vsHead().vsWalk(function (s) {
				s.vsDumpCounters(process.stderr);
			});
			console.error('----');
			dnStream.vsHead().vsWalk(function (s) {
				s.vsDumpDebug(process.stderr);
			});
		}
		process.exit(1);
	}
});

main();
